"""
æ•°æ®é‡‡é›†æœåŠ¡
"""
import asyncio
from datetime import datetime
from typing import Dict, List, Any
from loguru import logger

from app.database import get_db_context
from app.models import DataSource, MetricDefinition, MetricData, SyncLog


class DataCollector:
    """æ•°æ®é‡‡é›†å™¨"""
    
    def __init__(self):
        self.adapters = {
            "database_view": DatabaseViewAdapter(),
            "csv_file": CSVFileAdapter(),
            "excel_file": ExcelFileAdapter(),
            "json_file": JSONFileAdapter(),
        }
    
    async def collect_all(self):
        """é‡‡é›†æ‰€æœ‰æ•°æ®æº"""
        async with get_db_context() as db:
            # èŽ·å–æ‰€æœ‰æ´»è·ƒæ•°æ®æº
            from sqlalchemy import select
            result = await db.execute(
                select(DataSource).where(DataSource.status == "active")
            )
            sources = result.scalars().all()
            
            tasks = []
            for source in sources:
                task = self.collect_source(db, source)
                tasks.append(task)
            
            # å¹¶å‘æ‰§è¡Œ
            await asyncio.gather(*tasks, return_exceptions=True)
    
    async def collect_source(self, db, source: DataSource):
        """é‡‡é›†å•ä¸ªæ•°æ®æº"""
        logger.info(f"ðŸ“¥ å¼€å§‹é‡‡é›†æ•°æ®æº: {source.name} ({source.code})")
        
        sync_log = SyncLog(
            data_source_id=source.id,
            sync_type="incremental",
            start_time=datetime.utcnow(),
            status="running"
        )
        db.add(sync_log)
        await db.commit()
        
        try:
            # èŽ·å–é€‚é…å™¨
            adapter = self.adapters.get(source.source_type)
            if not adapter:
                raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æºç±»åž‹: {source.source_type}")
            
            # æ‰§è¡Œé‡‡é›†
            raw_data = await adapter.fetch(source)
            
            # å¤„ç†æ•°æ®
            metrics_data = await self.process_data(db, source, raw_data)
            
            # ä¿å­˜æŒ‡æ ‡æ•°æ®
            for metric_code, value in metrics_data.items():
                metric_data = MetricData(
                    metric_code=metric_code,
                    data_time=datetime.utcnow(),
                    value=value,
                    raw_data=raw_data.get(metric_code),
                    status="normal"
                )
                db.add(metric_data)
            
            # æ›´æ–°åŒæ­¥æ—¥å¿—
            sync_log.end_time = datetime.utcnow()
            sync_log.status = "success"
            sync_log.records_processed = len(metrics_data)
            
            # æ›´æ–°æ•°æ®æºçŠ¶æ€
            source.last_sync_time = datetime.utcnow()
            source.status = "active"
            source.error_message = None
            
            await db.commit()
            logger.info(f"âœ… æ•°æ®æº {source.name} é‡‡é›†å®Œæˆ, å¤„ç† {len(metrics_data)} æ¡æŒ‡æ ‡")
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®æº {source.name} é‡‡é›†å¤±è´¥: {e}")
            sync_log.end_time = datetime.utcnow()
            sync_log.status = "failed"
            sync_log.error_message = str(e)
            
            source.status = "error"
            source.error_message = str(e)
            
            await db.commit()
    
    async def process_data(self, db, source, raw_data: Dict) -> Dict[str, float]:
        """å¤„ç†åŽŸå§‹æ•°æ®,æå–æŒ‡æ ‡å€¼"""
        metrics_data = {}
        
        # èŽ·å–è¯¥æ•°æ®æºå…³è”çš„æŒ‡æ ‡
        from sqlalchemy import select
        result = await db.execute(
            select(MetricDefinition).where(
                MetricDefinition.data_source_id == source.id
            )
        )
        metrics = result.scalars().all()
        
        for metric in metrics:
            try:
                # æ ¹æ®æŒ‡æ ‡é…ç½®æå–å€¼
                value = self._extract_value(raw_data, metric)
                if value is not None:
                    metrics_data[metric.code] = value
            except Exception as e:
                logger.warning(f"æå–æŒ‡æ ‡ {metric.code} å€¼å¤±è´¥: {e}")
        
        return metrics_data
    
    def _extract_value(self, raw_data: Dict, metric) -> float:
        """ä»ŽåŽŸå§‹æ•°æ®ä¸­æå–æŒ‡æ ‡å€¼"""
        field_name = metric.field_name
        
        if metric.expression:
            # ä½¿ç”¨è¡¨è¾¾å¼è®¡ç®—
            return self._evaluate_expression(raw_data, metric.expression)
        
        # ç›´æŽ¥å–å€¼
        value = raw_data.get(field_name)
        if value is None:
            return None
        
        try:
            return float(value)
        except (ValueError, TypeError):
            return None
    
    def _evaluate_expression(self, raw_data: Dict, expression: str) -> float:
        """è®¡ç®—è¡¨è¾¾å¼"""
        # æ›¿æ¢å˜é‡
        expr = expression
        for key, value in raw_data.items():
            expr = expr.replace(f"{{{key}}}", str(value))
        
        # å®‰å…¨è®¡ç®—
        try:
            result = eval(expr, {"__builtins__": {}}, {})
            return float(result)
        except Exception as e:
            logger.warning(f"è¡¨è¾¾å¼è®¡ç®—å¤±è´¥: {expression}, error: {e}")
            return None


# ============================================================
# æ•°æ®æºé€‚é…å™¨
# ============================================================

class BaseAdapter:
    """é€‚é…å™¨åŸºç±»"""
    
    async def fetch(self, source) -> Dict[str, Any]:
        raise NotImplementedError


class DatabaseViewAdapter(BaseAdapter):
    """æ•°æ®åº“è§†å›¾é€‚é…å™¨"""
    
    async def fetch(self, source) -> Dict[str, Any]:
        import aiosqlite
        from app.config import DATABASE_URL
        
        conn_info = source.connection_info or {}
        db_path = conn_info.get("path")
        
        async with aiosqlite.connect(db_path) as conn:
            conn.row_factory = aiosqlite.Row
            cursor = await conn.execute("SELECT * FROM " + conn_info.get("view_name"))
            rows = await cursor.fetchall()
            
            if not rows:
                return {}
            
            # è¿”å›žç¬¬ä¸€è¡Œæ•°æ®
            row = rows[0]
            return {key: row[key] for key in row.keys()}


class CSVFileAdapter(BaseAdapter):
    """CSVæ–‡ä»¶é€‚é…å™¨"""
    
    async def fetch(self, source) -> Dict[str, Any]:
        import pandas as pd
        
        conn_info = source.connection_info or {}
        file_path = conn_info.get("path")
        
        if not file_path:
            return {}
        
        df = pd.read_csv(file_path)
        
        if df.empty:
            return {}
        
        # è¿”å›žæœ€åŽä¸€è¡Œ
        row = df.iloc[-1]
        return row.to_dict()


class ExcelFileAdapter(BaseAdapter):
    """Excelæ–‡ä»¶é€‚é…å™¨"""
    
    async def fetch(self, source) -> Dict[str, Any]:
        import pandas as pd
        
        conn_info = source.connection_info or {}
        file_path = conn_info.get("path")
        sheet_name = conn_info.get("sheet_name", 0)
        
        if not file_path:
            return {}
        
        df = pd.read_excel(file_path, sheet_name=sheet_name)
        
        if df.empty:
            return {}
        
        row = df.iloc[-1]
        return row.to_dict()


class JSONFileAdapter(BaseAdapter):
    """JSONæ–‡ä»¶é€‚é…å™¨"""
    
    async def fetch(self, source) -> Dict[str, Any]:
        import json
        
        conn_info = source.connection_info or {}
        file_path = conn_info.get("path")
        
        if not file_path:
            return {}
        
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        return data
